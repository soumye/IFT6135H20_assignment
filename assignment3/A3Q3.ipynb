{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glwbDyIca7u1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import q2_sampler\n",
    "\n",
    "from q3_sampler import svhn_sampler\n",
    "from q3_model import Critic, Generator\n",
    "from q2_solution_modified import lp_reg, vf_wasserstein_distance, vf_squared_hellinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "IwRiKrT2at6o",
    "outputId": "72f4f71d-6f2f-47bd-98a0-25315a38545a"
   },
   "outputs": [],
   "source": [
    "# Example of usage of the code provided and recommended hyper parameters for training GANs.\n",
    "data_root = './'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_iter = 50000 # N training iterations\n",
    "n_critic_updates = 5 # N critic updates per generator update\n",
    "lp_coeff = 10 # Lipschitz penalty coefficient\n",
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "lr = 1e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "z_dim = 100\n",
    "\n",
    "# Custom\n",
    "verbose = 20\n",
    "\n",
    "train_loader, valid_loader, test_loader = svhn_sampler(data_root, train_batch_size, test_batch_size)\n",
    "\n",
    "generator = Generator(z_dim=z_dim).to(device)\n",
    "critic = Critic().to(device)\n",
    "\n",
    "optim_critic = optim.Adam(critic.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optim_generator = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run if you want to load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zs1LZyl1O3iI",
    "outputId": "baf4e7a0-c776-4a7a-d0c5-205f5cc93f24"
   },
   "outputs": [],
   "source": [
    "# Load states\n",
    "ckpt = torch.load('wgan_lp_50000.ckpt')\n",
    "ckpt.keys()\n",
    "\n",
    "epoch = ckpt['epoch']\n",
    "\n",
    "generator.load_state_dict(ckpt['generator_state_dict'])\n",
    "optim_generator.load_state_dict(ckpt['optimizer_generator_state_dict'])\n",
    "\n",
    "critic.load_state_dict(ckpt['critic_state_dict'])\n",
    "optim_critic.load_state_dict(ckpt['optimizer_critic_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhwPFbApm65g"
   },
   "outputs": [],
   "source": [
    "train_iterator = iter(train_loader)\n",
    "c_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for step in range(epoch, n_iter):\n",
    "    for t in range(n_critic_updates):\n",
    "        # Update critic\n",
    "        optim_critic.zero_grad()\n",
    "\n",
    "        try:\n",
    "            x = next(train_iterator)[0].to(device)\n",
    "        except StopIteration:\n",
    "            train_iterator = iter(train_loader)\n",
    "            x = next(train_iterator)[0].to(device)\n",
    "        \n",
    "        z = torch.randn((train_batch_size, z_dim)).to(device)\n",
    "        y = generator(z)\n",
    "\n",
    "        loss = vf_wasserstein_distance(x, y, critic) + lp_coeff * lp_reg(x, y, critic, device=device)\n",
    "\n",
    "        # if step <= 5:\n",
    "        loss.backward()\n",
    "        optim_critic.step()\n",
    "        c_losses.append(loss[0])\n",
    "\n",
    "    # Update generator\n",
    "    optim_generator.zero_grad()\n",
    "    z = torch.randn((train_batch_size, z_dim)).to(device)\n",
    "    y = generator(z)\n",
    "    x = critic(y)\n",
    "\n",
    "    loss = x.mean()\n",
    "    loss.backward()\n",
    "    optim_generator.step()\n",
    "    g_losses.append(float(loss))\n",
    "\n",
    "    # Logging\n",
    "    if step % verbose == 0:\n",
    "        print(f\"Step #{step}. Generator Loss: {g_losses[-1]:.6f}. Critic Loss: {c_losses[-1]:.6f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhmQlURxNICT"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': 50000,\n",
    "    'critic_state_dict': critic.state_dict(),\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'optimizer_critic_state_dict': optim_critic.state_dict(),\n",
    "    'optimizer_generator_state_dict': optim_generator.state_dict(),\n",
    "    'critic_losses': c_losses,\n",
    "    'generator_losses': g_losses,\n",
    "    }, wgan_lp_50000.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5kHZAmpauSt"
   },
   "source": [
    "# Sample and display real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z86jDkO6XeJE"
   },
   "outputs": [],
   "source": [
    "train_iterator = iter(train_loader)\n",
    "x = next(train_iterator)[0].numpy()[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "7s0JFYcFXlr1",
    "outputId": "063cf45a-5c4a-467d-c4b9-57c02ceb7099"
   },
   "outputs": [],
   "source": [
    "reals = np.transpose(x, (0, 2, 3, 1))\n",
    "reals = reals * 0.5 + 0.5\n",
    "real_grid = reals.reshape(8, 4, 32, 32, 3)\n",
    "\n",
    "fig, axes =  plt.subplots(8, 4, figsize=(4, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(4):\n",
    "        axes[i, j].imshow(real_grid[i, j])\n",
    "        axes[i, j].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFHHHt5PaxGJ"
   },
   "source": [
    "# Sample and display fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "kowB0HI2ZRzG",
    "outputId": "06529e12-6f93-4140-a399-6efbaf93b8d6"
   },
   "outputs": [],
   "source": [
    "z = torch.randn((32, z_dim)).to(device)\n",
    "x = generator(z).detach().cpu().numpy()\n",
    "\n",
    "fakes = np.transpose(x, (0, 2, 3, 1))\n",
    "fakes = fakes * 0.5 + 0.5\n",
    "\n",
    "fakes_grid = fakes.reshape(8, 4, 32, 32, 3)\n",
    "fig, axes =  plt.subplots(8, 4, figsize=(4, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(4):\n",
    "        axes[i, j].imshow(fakes_grid[i, j])\n",
    "        axes[i, j].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgjDZkreWZlG"
   },
   "source": [
    "# Q3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BxyBzb4Lav2j"
   },
   "source": [
    "## First display the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "Q8wpBi8YWaMY",
    "outputId": "c0cff59f-8fd6-464b-fa2f-5a201fd91266"
   },
   "outputs": [],
   "source": [
    "z = torch.randn((1, z_dim)).to(device)\n",
    "x = generator(z).detach().cpu().numpy()\n",
    "\n",
    "orig = np.transpose(x, (0, 2, 3, 1))\n",
    "orig = orig * 0.5 + 0.5\n",
    "\n",
    "plt.imshow(orig[0])\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_PB6brxayST"
   },
   "source": [
    "## Now, add in the perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLKXGoUCXuG6"
   },
   "outputs": [],
   "source": [
    "eps_ratio = 1\n",
    "\n",
    "z_range = z.max() - z.min()\n",
    "eps = eps_ratio * z_range\n",
    "eps = torch.eye(z_dim, z_dim) * eps\n",
    "eps = eps.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ws4NjKCG-WIC"
   },
   "outputs": [],
   "source": [
    "z_pert = z + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NfeXIPXq0a0Z",
    "outputId": "f32bea97-8fa6-4e84-d30f-86d248d36ba8"
   },
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_x20u6Ic-yL2"
   },
   "outputs": [],
   "source": [
    "x_pert = generator(z_pert).detach().cpu().numpy()\n",
    "\n",
    "pert = np.transpose(x_pert, (0, 2, 3, 1))\n",
    "pert = pert * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVWf1Vj-aZx5"
   },
   "outputs": [],
   "source": [
    "pert_grid = pert.reshape(20, 5, 32, 32, 3)\n",
    "\n",
    "fig, axes =  plt.subplots(20, 5, figsize=(5, 20), squeeze=True)\n",
    "\n",
    "for i in range(20):\n",
    "    for j in range(5):\n",
    "        axes[i, j].imshow(pert_grid[i, j])\n",
    "        axes[i, j].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB313kT__UJ4"
   },
   "outputs": [],
   "source": [
    "select_pert = [\n",
    "    [\n",
    "        pert_grid[18, 3], # background color\n",
    "        pert_grid[2, 3], # 0\n",
    "        pert_grid[19, 0], # 7\n",
    "    ], [\n",
    "        pert_grid[1, 1], # erased\n",
    "        pert_grid[3, 1], # 1\n",
    "        pert_grid[2, 0], # 8\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "7yx7SPdpBQJG",
    "outputId": "fe45a73b-e226-4d8c-906a-d4d1da88915b"
   },
   "outputs": [],
   "source": [
    "fig, axes =  plt.subplots(2, 3, figsize=(3, 2), squeeze=True)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axes[i, j].imshow(select_pert[i][j])\n",
    "        axes[i, j].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knt0Lz1pC7Qy"
   },
   "source": [
    "# 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tumMP8HfC6LM"
   },
   "outputs": [],
   "source": [
    "z0 = torch.randn((1, z_dim)).to(device)\n",
    "z1 = torch.randn((1, z_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXqFd_daG1us"
   },
   "outputs": [],
   "source": [
    "x0 = generator(z0)\n",
    "img0 = np.transpose(x0.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "img0 = img0 * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yamd09U0G9y8"
   },
   "outputs": [],
   "source": [
    "x1 = generator(z1)\n",
    "img1 = np.transpose(x1.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "img1 = img1 * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "dsWlqUP7GvjN",
    "outputId": "9d089b66-6067-4f32-cd24-94c87acb308f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img0[0])\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "XhwAEIMIHCvV",
    "outputId": "1148aa2a-b90a-4cc6-98ec-b29e47083477"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img1[0])\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3AvFwRJHnr9"
   },
   "source": [
    "# 3.3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_8ijlHpHHCy"
   },
   "outputs": [],
   "source": [
    "alphas = torch.arange(0, 1.01, 0.1).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DV7SySBPIQ4P"
   },
   "outputs": [],
   "source": [
    "z_interp = alphas * z0 + (1-alphas) * z1\n",
    "\n",
    "x_interp = generator(z_interp)\n",
    "interp = np.transpose(x_interp.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "interp = interp * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "-QgJL-IjJPAf",
    "outputId": "03e4f1b6-ae11-4be6-ea12-96c3addb02b5"
   },
   "outputs": [],
   "source": [
    "fig, axes =  plt.subplots(1, 11, figsize=(11, 1), squeeze=True)\n",
    "\n",
    "for j in range(11):\n",
    "    axes[j].imshow(interp[j])\n",
    "    axes[j].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrbbT8mGLNAQ"
   },
   "source": [
    "# 3.3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tqh0JRxLf34"
   },
   "outputs": [],
   "source": [
    "beta = alphas.view(11, 1, 1, 1)\n",
    "x0 = x_interp[-1]\n",
    "x1 = x_interp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g24a4TCYKuUp"
   },
   "outputs": [],
   "source": [
    "x_interp = beta * x0 + (1 - beta) * x1\n",
    "interp = np.transpose(x_interp.detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "interp = interp * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "iaUlBT49LZru",
    "outputId": "069937ea-487a-478d-b0da-e12e0c1c22c0"
   },
   "outputs": [],
   "source": [
    "fig, axes =  plt.subplots(1, 11, figsize=(11, 1), squeeze=True)\n",
    "\n",
    "for j in range(11):\n",
    "    axes[j].imshow(interp[j])\n",
    "    axes[j].axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of A3Q3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
